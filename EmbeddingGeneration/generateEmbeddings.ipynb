{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings using SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure to have data/collection.tsv in the same folder as this file\n",
    "- The embeddings are generated in the folder embeddings/ with the name corpus_embeddings_{k} where k is an integer\n",
    "- We have split the data into chunks of 200k passages each for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file for the entire corpus of passages\n",
    "corpus = ['']\n",
    "with open(\"data/collection.tsv\") as fd:\n",
    "    passageData = csv.reader(fd, delimiter=\"\\t\")\n",
    "    for line in passageData:\n",
    "        corpus.append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk them so that they can be processed efficiently\n",
    "len(corpus)\n",
    "chunk_size = 200000\n",
    "corpus_list = [list(filter(None, group)) for group in zip_longest(*[iter(corpus)] * chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase you have already created the corpus uncomment and use the below line\n",
    "# with open('./embeddings/corpus', 'rb') as f:\n",
    "#     corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(45):\n",
    "        corpus_embeddings = embedder.encode(corpus_list[i], convert_to_tensor=True)\n",
    "        with open('./embeddings/corpus_embeddings_'+str(i), 'wb') as file:\n",
    "                pickle.dump(corpus_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array saved\n"
     ]
    }
   ],
   "source": [
    "del corpus_embeddings\n",
    "del corpus\n",
    "print(f\"Array saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/18fj_n894sb39k_1hmrch5380000gn/T/ipykernel_27503/1362246920.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  corpus_embeddings = torch.tensor(corpus_embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined corpus embeddings saved to ./embeddings/combined_corpus_embeddings\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "combined_corpus_embeddings = None\n",
    "for k in range(45):\n",
    "    file_name = f'./embeddings/corpus_embeddings_{k}'\n",
    "    with open(file_name, 'rb') as file:\n",
    "        corpus_embeddings = pickle.load(file)\n",
    "        corpus_embeddings = torch.tensor(corpus_embeddings)\n",
    "        if combined_corpus_embeddings is None:\n",
    "            combined_corpus_embeddings = corpus_embeddings\n",
    "        else:\n",
    "            combined_corpus_embeddings = torch.cat((combined_corpus_embeddings, corpus_embeddings), dim=0)\n",
    "\n",
    "output_file = './embeddings/combined_corpus_embeddings'\n",
    "with open(output_file, 'wb') as file:\n",
    "    pickle.dump(combined_corpus_embeddings, file)\n",
    "\n",
    "print(f\"Combined corpus embeddings saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
